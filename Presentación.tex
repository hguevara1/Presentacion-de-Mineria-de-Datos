\documentclass{beamer}
\usetheme{Madrid}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{cite}

\title[Minería de Datos - Cancer Data]{Aplicación de la Metodología CRISP-DM para el Análisis de Datos de Cáncer}
\author{Guevara - Hernández}
\institute{UCV}
\date{2025}

\begin{document}
	
	\begin{frame}
		\titlepage
	\end{frame}
	
	\begin{frame}{Introducción}
		La minería de datos se define como el proceso de descubrir conocimiento o patrones implícitos, desconocidos y potencialmente útiles a partir de los datos [1], [2]. En este proyecto, aplicamos este proceso a un conjunto de datos médicos para facilitar la toma de decisiones clínicas [3].
	\end{frame}
	
	% --- JUSTIFICACIÓN PARTE 1 ---
	\begin{frame}{Justificación de CRISP-DM (I)}
		La elección de CRISP-DM como marco de trabajo se fundamenta en su posición como estándar de facto en la industria [3, 4].
		\begin{itemize}
			\item<1-> \textbf{Orientación al Negocio:} A diferencia de modelos puramente técnicos como SEMMA, CRISP-DM inicia con el entendimiento de los objetivos comerciales y criterios de éxito [3, 5].
			\item<2-> \textbf{Reducción de Riesgos:} Sistematiza el desarrollo, lo que permite minimizar las probabilidades de reprocesos costosos durante el ciclo de vida del proyecto [6].
		\end{itemize}
	\end{frame}
	
	% --- JUSTIFICACIÓN PARTE 2 ---
	\begin{frame}{Justificación de CRISP-DM (II)}
		\begin{itemize}
			\item<1-> \textbf{Ciclo Iterativo y Flexible:} Su naturaleza no es lineal; permite retroceder entre fases (ej. del Modelado a la Preparación de Datos) según los hallazgos técnicos [7, 8].
			\item<2-> \textbf{Visión de Despliegue:} Incluye explícitamente el mantenimiento y monitoreo, fases críticas para gestionar la "deuda técnica" en sistemas de aprendizaje automático [9, 10].
			\item<3-> \textbf{Interdisciplinariedad:} Facilita la colaboración entre expertos del dominio y analistas de datos [11, 12].
		\end{itemize}
	\end{frame}
	
	% --- FASES PARTE 1: ENTENDIMIENTO ---
	\begin{frame}{Etapas de CRISP-DM (I): Entendimiento}
		Las fases iniciales sientan las bases del conocimiento necesario para el éxito del proyecto [13].
		\begin{enumerate}
			\item<1-> \textbf{Entendimiento del Negocio:}
			\begin{itemize}
				\item Definición de objetivos cuantificables.
				\item Evaluación de recursos, riesgos y relación costo-beneficio [14].
			\end{itemize}
			\item<2-> \textbf{Entendimiento de los Datos:}
			\begin{itemize}
				\item Recolección inicial y descripción de atributos.
				\item Análisis de calidad (identificación de valores nulos, anómalos o sesgos) [13, 15].
			\end{itemize}
		\end{enumerate}
	\end{frame}
	
	% --- FASES PARTE 2: PREPARACIÓN Y MODELADO ---
	\begin{frame}{Etapas de CRISP-DM (II): Acción Técnica}
		En esta etapa se concentra el mayor esfuerzo computacional y analítico [16, 17].
		\begin{enumerate}
			\setcounter{enumi}{2}
			\item \textbf{Preparación de los Datos:}
			\begin{itemize}
				\item Preprocesamiento estructural (\textit{Tidy Data}) y funcional (escalamiento, codificación) [18, 19].
				\item Representa aproximadamente el 80\% del tiempo del proyecto [16, 20].
			\end{itemize}
			\item<2-> \textbf{Modelado:}
			\begin{itemize}
				\item Selección de algoritmos (clasificación, regresión, agrupación).
				\item Configuración de hiperparámetros y diseño de pruebas de robustez [21, 22].
			\end{itemize}
		\end{enumerate}
	\end{frame}
	
	% --- FASES PARTE 3: EVALUACIÓN Y DESPLIEGUE ---
	\begin{frame}{Etapas de CRISP-DM (III): Cierre y Valor}
		Se verifica que el conocimiento extraído sea realmente útil y aplicable [5, 23].
		\begin{enumerate}
			\setcounter{enumi}{4}
			\item \textbf{Evaluación del Modelo:}
			\begin{itemize}
				\item Comparación de resultados frente a los objetivos de negocio.
				\item Análisis de métricas técnicas (Precisión, F1-Score) y lógicas [5, 24].
			\end{itemize}
			\item<2-> \textbf{Despliegue:}
			\begin{itemize}
				\item Plan de implementación (APIs, integración en sistemas).
				\item Reporte final, documentación técnica y plan de mantenimiento [5, 24].
			\end{itemize}
		\end{enumerate}
	\end{frame}
	
	% --- LÁMINA 1: DESCRIPCIÓN Y ATRIBUTOS ---
	\begin{frame}{ Estructura y Características del Dataset}
		Este conjunto de datos (\href{https://www.kaggle.com/datasets/erdemtaha/cancer-data}{Aquí el link})  se compone de características visuales extraídas de muestras celulares para el diagnóstico clínico de cáncer de mama,.
		\begin{itemize}
			\item \textbf{Identificador (id):} Código único para cada paciente (no predictivo),.
			\item \textbf{Variable Objetivo (diagnosis):} Clasificación binaria categórica con estados:
			\begin{itemize}
				\item \textbf{M} (Maligno - Cáncer presente).
				\item \textbf{B} (Benigno - Ausencia de malignidad).
			\end{itemize}
			\item \textbf{Características Visuales (Valores Medios):} Atributos como radio\_media, textura\_media, perímetro\_media, área\_media, suavidad\_media, compacidad\_media, concavidad\_media y puntos cóncavos\_media,.
			\item \textbf{Atributos Categóricos:} Incluye variables etiquetadas con valores numéricos para análisis estadístico,.
		\end{itemize}
	\end{frame}
	
	% --- LÁMINA 2: UTILIDAD Y PREPROCESAMIENTO ---
	\begin{frame}{Utilidad del Dataset y Análisis Exploratorio (EDA)}
		El propósito fundamental es el entrenamiento y validación de algoritmos de diagnóstico médico asistido por computadora,.
		\begin{itemize}
			\item \textbf{Distribución de Rangos:} Cada característica se asigna a tablas de frecuencia que contienen la cantidad de valores en rangos específicos,.
			\item \textbf{Análisis Visual:} El uso de histogramas permite examinar la dispersión de las medias visuales del cáncer para detectar grupos naturales,.
			\item \textbf{Preprocesamiento Sugerido:} Debido a que las características numéricas tienen rangos dispares (ej. área vs suavidad), es necesario aplicar \textit{escalamiento funcional} (Standardization) para garantizar la convergencia de los modelos,.
		\end{itemize}
	\end{frame}
	
	% --- LÁMINA 3: CASOS DE USO (MODELADO) ---
	\begin{frame}{Fase 4: Casos de Uso de Algoritmos Predictivos}
		Basado en la naturaleza binaria y visual del dataset, se proponen los siguientes enfoques de modelado bajo supervisión,:
		\begin{itemize}
			\item \textbf{Regresión Logística:} Ideal para clasificación binaria (M vs B). Permite predecir el tipo de cáncer basándose en la relación lineal de las características visuales,.
			\item \textbf{K-Vecinos más cercanos (k-NN):} Clasifica muestras analizando la similitud entre pacientes cercanos. Se asume que características visuales similares tienden a diagnósticos iguales,.
			\item \textbf{Máquinas de Vectores de Soporte (SVM):} Algoritmo potente para la separación clara de clases en espacios de alta dimensionalidad, optimizando el margen de decisión médico,.
		\end{itemize}
	\end{frame}
		
	
	\begin{frame}{Fase 1: Entendimiento del Negocio y los Datos}
		Según el estándar CRISP-DM, antes de cualquier procesamiento técnico, se deben ejecutar las siguientes acciones estratégicas sobre el dataset de \textit{Cancer Data} [1], [3]:
		
		\begin{itemize}
			\item \textbf{Establecimiento de Objetivos:} Definir el problema como una tarea de \textit{clasificación binaria} para predecir la malignidad de un tumor basándose en atributos celulares [4], [1].
			\item \textbf{Criterios de Éxito:} Determinar métricas de rendimiento críticas. En este contexto médico, es vital minimizar los \textit{falsos negativos} mediante el análisis de la Matriz de Confusión y el F1-Score [5], [6].
			\item \textbf{Reporte de Calidad de Datos:} Realizar una auditoría inicial para detectar:
			\begin{itemize}
				\item Presencia de valores nulos o ausentes que requieran imputación [7], [8].
				\item Consistencia en el formato de las variables numéricas (radio, textura, perímetro) [9], [10].
				\item Identificación de \textit{outliers} que puedan sesgar el modelo predictivo [11], [12].
			\end{itemize}
		\end{itemize}
	\end{frame}
	
	% --- LÁMINA 1: AUDITORÍA DE CALIDAD EXTENDIDA ---
	\begin{frame}{Auditoría de Calidad Extendida (Fase 2)}
		Además de los nulos y outliers, se deben verificar los siguientes criterios estáticos para asegurar la integridad del análisis,:
		\begin{itemize}
			\item \textbf{Valores Duplicados:} Detectar y consolidar registros idénticos que puedan causar confusión y sesgar el rendimiento del modelo,.
			\item \textbf{Verificación de Tipos:} Garantizar que cada atributo (booleano, numérico, categórico) sea consistente con el significado documentado,.
			\item \textbf{Distribución Estadística:} Evaluar el sesgo (\textit{skew}) y la curtosis de las variables numéricas; distribuciones extremas (sesgo $>1$, curtosis $>7$) sugieren el uso de algoritmos simbólicos en lugar de estadísticos,.
			\item \textbf{Vigencia de los Datos:} Confirmar que las observaciones coinciden con la ventana de tiempo que se desea analizar para evitar el uso de información caduca,.
		\end{itemize}
	\end{frame}
	
	% --- LÁMINA 2: ANÁLISIS DE REDUNDANCIA ---
	\begin{frame}{Análisis de Interdependencia y Redundancia}
		Antes del modelado, es crítico evaluar la relación entre variables numéricas (como radio y perímetro),:
		\begin{itemize}
			\item \textbf{Colinealidad:} La alta correlación entre variables dificulta la atribución del comportamiento a un atributo específico y hace inestables a algunas técnicas de modelado,.
			\item \textbf{Variables No Informativas:} Identificar y eliminar variables con varianza cero o redundantes que consumen recursos computacionales innecesarios sin aportar valor predictivo,.
			\item \textbf{Uso de PCA:} En casos de alta dimensionalidad, considerar la reducción por proyección mediante Análisis de Componentes Principales para capturar la mayor varianza posible en un espacio más pequeño,.
		\end{itemize}
	\end{frame}
	
	% --- LÁMINA 3: PREPROCESAMIENTO ESTRUCTURAL ---
	\begin{frame}{Preprocesamiento Estructural (Tidy Data)}
		Para que el dataset sea procesable por librerías como \textit{scikit-learn}, debe cumplir con los principios de \textit{Tidy Data},:
		\begin{itemize}
			\item \textbf{Encapsulamiento:} Garantizar que cada fenómeno (ej. medición celular) esté en una única tabla y cada observación en una sola fila,.
			\item \textbf{Normalización Estructural:} Cada variable debe estar documentada en una columna única, evitando que los descriptores de columna sean en realidad valores de una variable,.
			\item \textbf{Consistencia de Significado:} La representación física de los datos debe ser consistente con la semántica del dominio médico (ej. unidades de medida uniformes),.
		\end{itemize}
	\end{frame}
	

	\begin{frame}{Análisis Exploratorio de Datos (EDA)}
		El EDA es fundamental para comprender las dinámicas del dataset [14].
		\begin{itemize}
			\item \textbf{Distribuciones:} Uso de histogramas o diagramas de densidad para observar la dispersión de las variables cuantitativas [14], [15].
			\item<2-> \textbf{Correlaciones:} Implementación de mapas de calor (Heatmaps) para detectar colinealidad entre atributos numéricos (ej. relación entre radio y perímetro) [16], [17].
			\item<3-> \textbf{Discriminación:} Comparar las características medias entre el subgrupo de tumores benignos frente a malignos [18], [19].
		\end{itemize}
	\end{frame}
	
	\section{3. Preparación de los Datos}
	\begin{frame}{Fase 3: Preparación de Datos (Preprocesamiento)}
		Es la etapa que más tiempo consume, asegurando que los datos sean estructural y funcionalmente correctos [20], [21].
		\begin{itemize}
			\item \textbf{Preprocesamiento Estructural:} Garantizar el formato \textit{Tidy Data} (una variable por columna, una observación por fila) [22], [23].
			\item<2-> \textbf{Preprocesamiento Funcional:}
			\begin{itemize}
				\item \textbf{Escalamiento:} Aplicar \textit{StandardScaler} o \textit{MinMaxScaler} para que las variables tengan rangos comparables [24], [25].
				\item \textbf{Codificación:} Transformar la variable objetivo (Diagnosis) de categórica a numérica (0/1) para el modelado [24], [26].
				\item \textbf{Reducción de Dimensionalidad:} Evaluar el uso de PCA para reducir el ruido si existen atributos altamente correlacionados [27], [28].
			\end{itemize}
		\end{itemize}
	\end{frame}
	
	\section{4. Modelado}
	\begin{frame}{Fase 4: Modelado}
		Selección y aplicación de algoritmos especializados [6], [8].
		\begin{itemize}
			\item \textbf{Tarea:} Clasificación (Aprendizaje Supervisado) [7], [29].
			\item<2-> \textbf{Algoritmos Candidatos:}
			\begin{itemize}
				\item \textbf{k-NN:} Efectivo si los atributos están igualmente escalados [30], [31].
				\item \textbf{Regresión Logística:} Proporciona una separación lineal robusta para variables binarias [30], [32].
				\item \textbf{Árboles de Decisión (CART):} Ofrece alta interpretabilidad para el personal médico [30], [33].
			\end{itemize}
		\end{itemize}
	\end{frame}
	
	\section{5. Evaluación y Despliegue}
	\begin{frame}{Fase 5 y 6: Evaluación y Despliegue}
		\begin{itemize}
			\item \textbf{Evaluación:} Uso de \textit{Cross-Validation} para garantizar la fiabilidad de las métricas obtenidas [34], [35]. Análisis de la matriz de confusión para minimizar falsos negativos (casos de cáncer no detectados) [9].
			\item<2-> \textbf{Despliegue:} Planificar la integración del modelo mediante una API o reporte final para su uso en entornos productivos [36], [37].
			\item<3-> \textbf{Deuda Técnica:} Considerar factores de riesgo como la dependencia de datos inestables y la necesidad de monitoreo constante de la precisión [38], [39].
		\end{itemize}
	\end{frame}
	
	\begin{frame}{Bibliografía}
		\begin{thebibliography}{10}
			\bibitem{Han2012} J. Han, M. Kamber y J. Pei, \textit{Data mining concepts and techniques}, 3ra ed., 2012.
			\bibitem{Wirth2000} R. Wirth y J. Hipp, ``CRISP-DM: Towards a Standard Process Model for Data Mining'', 2000.
			\bibitem{Sculley2015} D. Sculley et al., ``Hidden Technical Debt in Machine Learning Systems'', 2015.
			\bibitem{King1995} R. D. King et al., ``STATLOG: Comparison of Classification Algorithms on Large Real-World Problems'', 1995.
			\bibitem{Gonzalez2025} W. González, ``Proceso de Minería de Datos'', \textit{6213 - Facultad de Ciencias UCV}, 2025 [1, 16].
			\bibitem{Martins2016} S. Martins et al., ``Propuesta de Artefactos para el Subproceso de Gestión de Proyectos de Explotación de Información'', \textit{SEDICI - UNLP}, 2016 [17].
			\bibitem{Wickham2014} H. Wickham, ``Tidy Data'', \textit{Journal of Statistical Software}, 2014.
			\bibitem{Sculley2015} D. Sculley et al., ``Hidden Technical Debt in Machine Learning Systems'', 2015.
		\end{thebibliography}
	\end{frame}
	
\end{document}
